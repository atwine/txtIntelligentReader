# ‚ùì Frequently Asked Questions (FAQ)

**Common questions and answers about txtIntelligentReader**

## Table of Contents

1. [General Questions](#general-questions)
2. [Technical Questions](#technical-questions)
3. [Performance Questions](#performance-questions)
4. [Usage Questions](#usage-questions)
5. [Troubleshooting Questions](#troubleshooting-questions)
6. [Development Questions](#development-questions)

## General Questions

### What is txtIntelligentReader?

**Q: What exactly does txtIntelligentReader do?**

A: txtIntelligentReader is an advanced medical text processing system that extracts high-quality, medically relevant sentences from noisy text documents. It uses a 4-layer filtering approach to clean up documents like PDFs, research papers, and clinical notes, making them ready for translation or further processing.

**Q: What makes it different from other text processing tools?**

A: Key differentiators:
- **Medical Domain Specialization**: Optimized specifically for healthcare content
- **Multi-Layer Filtering**: 4 sequential filters remove different types of noise
- **High Performance**: Processes 150,000+ sentences per minute
- **Offline Operation**: No external APIs required
- **Comprehensive Testing**: 100+ test scenarios ensure reliability
- **Multiple Output Formats**: Text, JSON, Markdown, CSV, and HTML

**Q: Who should use txtIntelligentReader?**

A: Ideal for:
- **Medical Translators**: Preparing clinical documents for translation
- **Healthcare Researchers**: Cleaning research papers and clinical data
- **Medical Writers**: Processing and standardizing medical content
- **Data Scientists**: Preprocessing medical text datasets
- **Healthcare Organizations**: Standardizing clinical documentation

### What types of documents work best?

**Q: What file formats are supported?**

A: Currently supports plain text files (`.txt`). The content can originate from:
- PDF exports (after conversion to text)
- Medical records and clinical notes
- Research papers and publications
- Healthcare documentation
- Patient information sheets
- Medical training materials

**Q: What languages are supported?**

A: Currently optimized for English medical text. The system uses English medical terminology and grammar rules. Other languages may work but with reduced accuracy.

**Q: Can I process non-medical text?**

A: Yes, but the system is optimized for medical content. Non-medical text will be processed, but many sentences may be filtered out due to the health domain focus. You can adjust thresholds to be more lenient:

```bash
python src/main.py input.txt -o output.txt --health-threshold 0.05
```

## Technical Questions

### System Requirements

**Q: What are the minimum system requirements?**

A: **Minimum**:
- Python 3.8+
- 4GB RAM
- 2GB storage
- Windows 10+, macOS 10.14+, or Linux (Ubuntu 18.04+)

**Recommended**:
- Python 3.9+
- 8GB+ RAM
- 5GB storage
- Multi-core processor

**Q: Do I need an internet connection?**

A: No! txtIntelligentReader works completely offline. It doesn't make any external API calls or require internet connectivity.

**Q: What dependencies are required?**

A: Only Python standard library modules. No external APIs, databases, or complex dependencies. See `requirements.txt` for the complete list.

### Architecture

**Q: How does the 4-layer filtering work?**

A: The system processes text through four sequential layers:

1. **Quick Filter**: Removes obvious noise (headers, footers, page numbers, formatting artifacts)
2. **Health Context Filter**: Identifies and scores medical relevance using terminology databases
3. **AI Analysis Filter**: Analyzes sentence completeness and logical structure
4. **Complete Thought Validator**: Ensures sentences express complete, actionable thoughts

**Q: Can I customize the filtering layers?**

A: Yes! You can:
- Adjust thresholds for each layer
- Modify medical terminology databases
- Extend filter logic in the source code
- Create custom configuration files

**Q: How accurate is the medical content detection?**

A: Based on testing:
- **False Positive Rate**: 0.0% (excellent at filtering non-medical content)
- **False Negative Rate**: 40.0% with default settings (can be improved by lowering thresholds)
- **Precision**: High for clearly medical content
- **Recall**: Can be tuned based on your needs

## Performance Questions

### Processing Speed

**Q: How fast is txtIntelligentReader?**

A: Performance benchmarks:
- **Processing Speed**: 150,000+ sentences per minute
- **Memory Usage**: <100KB per sentence
- **Scalability**: Handles 20,000+ sentences in single run
- **Concurrent Processing**: Thread-safe multi-file processing

**Q: What's the largest file I can process?**

A: Successfully tested with:
- **20,000+ sentences** in a single file
- **50MB+ text files**
- **Multiple concurrent files**

For larger files, consider splitting them into smaller chunks.

**Q: How can I improve processing speed?**

A: Speed optimization tips:
```bash
# Use text output (fastest)
python src/main.py input.txt -o output.txt --format txt

# Lower thresholds (less processing)
python src/main.py input.txt -o output.txt --health-threshold 0.1

# Avoid debug mode for production
python src/main.py input.txt -o output.txt  # No --debug
```

### Memory Usage

**Q: How much memory does it use?**

A: Memory usage scales with file size:
- **Small files** (<1MB): <50MB RAM
- **Medium files** (1-10MB): <200MB RAM
- **Large files** (10-50MB): <1GB RAM

**Q: What if I run out of memory?**

A: Solutions:
1. **Split large files**: `split -l 2000 input.txt chunk_`
2. **Use text output only**: `--format txt`
3. **Avoid debug mode**: Remove `--debug` flag
4. **Process in batches**: Handle multiple smaller files

## Usage Questions

### Basic Usage

**Q: What's the simplest way to get started?**

A: Three-step quick start:
```bash
# 1. Install
pip install -r requirements.txt

# 2. Create test file
echo "The patient has diabetes and hypertension." > test.txt

# 3. Process
python src/main.py test.txt -o output.txt --stats
```

**Q: How do I choose the right thresholds?**

A: Threshold guidelines:

**For Research/Analysis** (keep more content):
```bash
--health-threshold 0.1 --quality-threshold 0.3 --completeness-threshold 0.2
```

**For Translation** (balanced quality):
```bash
--health-threshold 0.15 --quality-threshold 0.5 --completeness-threshold 0.4
```

**For High-Quality Output** (strict filtering):
```bash
--health-threshold 0.4 --quality-threshold 0.8 --completeness-threshold 0.7
```

**Q: Which output format should I use?**

A: Format recommendations:
- **Text (`.txt`)**: For simple, clean output
- **JSON (`.json`)**: For programmatic integration
- **Markdown (`.md`)**: For detailed reports with formatting
- **CSV (`.csv`)**: For statistical analysis
- **HTML (`.html`)**: For interactive web reports

### Advanced Usage

**Q: How do I process multiple files?**

A: Batch processing example:
```bash
# Process all .txt files in a directory
for file in input/*.txt; do
    basename=$(basename "$file" .txt)
    python src/main.py "$file" -o "output/${basename}_processed.txt"
done
```

**Q: Can I integrate this into my existing workflow?**

A: Yes! Integration examples:

**Python Script**:
```python
import subprocess
import json

result = subprocess.run([
    'python', 'src/main.py', 'input.txt', 
    '-o', 'output.json', '--format', 'json'
], capture_output=True, text=True)

with open('output.json', 'r') as f:
    data = json.load(f)
    sentences = data['results']['filtered_sentences']
```

**Command Line Pipeline**:
```bash
# Process and count results
python src/main.py input.txt -o output.txt --stats | grep "retained"
```

**Q: How do I customize the medical terminology?**

A: You can extend the medical terms list by modifying:
```python
# In src/filters/health_context_filter.py
MEDICAL_TERMS = [
    'diabetes', 'hypertension', 'myocardial infarction',
    # Add your terms here
    'your_custom_term', 'another_medical_term'
]
```

## Troubleshooting Questions

### Common Issues

**Q: Why is my output file empty?**

A: Most common cause is thresholds being too strict. Try:
```bash
python src/main.py input.txt -o output.txt \
  --health-threshold 0.05 \
  --quality-threshold 0.2 \
  --debug
```

Check the debug output to see where sentences are being filtered.

**Q: I'm getting "ModuleNotFoundError" errors. What's wrong?**

A: Common solutions:
1. **Check directory**: Ensure you're in the project root
2. **Check Python path**: `export PYTHONPATH="${PYTHONPATH}:$(pwd)"`
3. **Verify installation**: `pip install -r requirements.txt`
4. **Check file structure**: `ls src/` should show the main modules

**Q: Processing is very slow. How can I speed it up?**

A: Speed optimization:
1. **Check file size**: `ls -lh input.txt`
2. **Use simpler output**: `--format txt`
3. **Lower thresholds**: `--health-threshold 0.1`
4. **Split large files**: `split -l 1000 input.txt chunk_`
5. **Disable debug**: Remove `--debug` flag

**Q: I'm getting encoding errors. How do I fix them?**

A: Encoding solutions:
```bash
# Check file encoding
file -i input.txt

# Convert to UTF-8
iconv -f ISO-8859-1 -t UTF-8 input.txt > input_utf8.txt

# Set environment variable
export PYTHONIOENCODING=utf-8
```

### Quality Issues

**Q: The output quality isn't what I expected. How can I improve it?**

A: Quality improvement strategies:

1. **Adjust thresholds based on your needs**:
   - Lower thresholds for more content
   - Higher thresholds for better quality

2. **Use debug mode to understand filtering**:
   ```bash
   python src/main.py input.txt -o output.txt --debug
   ```

3. **Test with different threshold combinations**:
   ```bash
   # Test multiple settings
   for health in 0.1 0.2 0.3; do
     for quality in 0.3 0.5 0.7; do
       echo "Testing h=$health q=$quality"
       python src/main.py input.txt -o "test_${health}_${quality}.txt" \
         --health-threshold $health --quality-threshold $quality
     done
   done
   ```

**Q: How do I know if the filtering is working correctly?**

A: Validation approaches:

1. **Use statistics**: `--stats` flag shows retention rates
2. **Enable debug mode**: See detailed filtering decisions
3. **Manual review**: Check a sample of output sentences
4. **Compare thresholds**: Test different settings side-by-side

## Development Questions

### Extending the System

**Q: Can I add new filtering layers?**

A: Yes! The system is designed to be extensible:

1. **Create new filter class** in `src/filters/`
2. **Implement required interface** (process method)
3. **Add to pipeline** in `src/pipeline/filter_pipeline.py`
4. **Add tests** in `tests/`

**Q: How do I contribute to the project?**

A: Contribution process:

1. **Fork the repository**
2. **Create feature branch**: `git checkout -b feature/new-filter`
3. **Make changes and add tests**
4. **Run test suite**: `python -m pytest tests/`
5. **Submit pull request**

See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines.

**Q: Can I use this as a library in my Python project?**

A: Yes! Example integration:

```python
from src.pipeline.filter_pipeline import FilterPipeline
from src.pipeline.text_processor import TextProcessor

# Create processor
processor = TextProcessor()

# Process text
results = processor.process_text("Your medical text here")

# Access filtered sentences
sentences = results['filtered_sentences']
```

### Testing and Quality

**Q: How well tested is the system?**

A: Comprehensive test coverage:
- **100+ test scenarios** across all components
- **Unit tests**: Individual component testing
- **Integration tests**: End-to-end workflow testing
- **Performance tests**: Speed and memory benchmarks
- **Quality tests**: Medical content validation

**Q: How do I run the tests?**

A: Test execution:
```bash
# Run all tests
python -m pytest tests/ -v

# Run specific test categories
python tests/test_filters_unit.py
python tests/test_performance.py
python tests/test_quality_validation.py

# Run with coverage
python -m pytest tests/ --cov=src --cov-report=html
```

**Q: What's the test coverage?**

A: Current coverage:
- **Unit Tests**: 95%+ component coverage
- **Integration Tests**: All major workflows
- **Performance Tests**: Speed and memory validation
- **Quality Tests**: Medical content accuracy

### Future Development

**Q: What features are planned for future releases?**

A: Roadmap includes:
- **Multi-language support**: Spanish, French, German medical text
- **PDF direct processing**: Skip text conversion step
- **Web interface**: Browser-based processing
- **API endpoints**: REST API for integration
- **Machine learning**: Enhanced medical term recognition
- **Batch processing UI**: Graphical batch processing tool

**Q: How can I request new features?**

A: Feature request process:
1. **Check existing issues**: Search for similar requests
2. **Create detailed issue**: Describe use case and requirements
3. **Provide examples**: Show input/output expectations
4. **Discuss implementation**: Engage with maintainers

**Q: Is commercial use allowed?**

A: Yes! The project is licensed under MIT License, which allows:
- **Commercial use**
- **Modification**
- **Distribution**
- **Private use**

See [LICENSE](../LICENSE) file for complete terms.

---

**Still have questions?** 

- Check the [User Guide](user-guide.md) for detailed usage instructions
- Review [Troubleshooting Guide](TROUBLESHOOTING.md) for common issues
- Search [existing issues](../../issues) on GitHub
- Create a [new issue](../../issues/new) with your question

We're here to help! üöÄ
